{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eb71d3f",
   "metadata": {},
   "source": [
    "# Testing Environment\n",
    "This notebook is used for experimenting code blocks and performing tuning operations for models. It currently contains successful trials in all cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47404caf",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab7a4d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries and tools                                                        Purpose\n",
    "import os #__________________________________________________________________Operating system manipulation\n",
    "import sys #_________________________________________________________________System-specific parameters\n",
    "import numpy as np #_________________________________________________________Numerical computations\n",
    "import pandas as pd #________________________________________________________Data structures\n",
    "from datetime import datetime #____________________________________________________________Data involving time\n",
    "import textwrap #____________________________________________________________Line formatting\n",
    "import matplotlib.pyplot as plt #____________________________________________Statistic visualizations\n",
    "import seaborn as sns #______________________________________________________\"\n",
    "import joblib #______________________________________________________________Exporting ML models\n",
    "from sklearn.cluster import KMeans #_________________________________________Clustering modeling\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression #______Base ML models\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier #_____Tree models\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier #_\"\n",
    "from xgboost import XGBRegressor, XGBClassifier #____________________________Boost models\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier #_________________________\"\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier #_________________\"\n",
    "from sklearn.pipeline import Pipeline #______________________________________Pipeline preprocessing\n",
    "from sklearn.compose import ColumnTransformer #______________________________\"\n",
    "from sklearn.impute import SimpleImputer #___________________________________\"\n",
    "from sklearn.preprocessing import (StandardScaler, MinMaxScaler, #___________Preprocessing data scalers\n",
    "    OneHotEncoder, LabelEncoder, PolynomialFeatures) #_______________________Feature engineering\n",
    "from scipy import stats #____________________________________________________Probability and stat tests\n",
    "from sklearn.model_selection import (train_test_split, cross_val_score, #____Model training & validation\n",
    "    GridSearchCV, RandomizedSearchCV, StratifiedKFold) #_____________________\"\n",
    "from sklearn.metrics import (log_loss, r2_score, mean_squared_error, #_______Model evaluation\n",
    "    root_mean_squared_error, accuracy_score, f1_score, precision_score, #____\"\n",
    "    recall_score, confusion_matrix, classification_report) #_________________\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8ace43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models():\n",
    "    base_path = 'ml_models/'\n",
    "    return {\n",
    "        \"Logistic Regression\": joblib.load(os.path.join(base_path, 'logistic_regression.pkl')),\n",
    "        \"Decision Tree\": joblib.load(os.path.join(base_path, 'decision_tree.pkl')),\n",
    "        \"Random Forest\": joblib.load(os.path.join(base_path, 'random_forest.pkl')),\n",
    "        \"XG Boosting\": joblib.load(os.path.join(base_path, 'xgboost.pkl')),\n",
    "        \"LightGBM\": joblib.load(os.path.join(base_path, 'lightgbm.pkl')),\n",
    "        \"CatBoost\": joblib.load(os.path.join(base_path, 'catboost.pkl'))\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4681f7ea",
   "metadata": {},
   "source": [
    "## Import and Inspect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16476daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11997 entries, 0 to 11996\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Timestamp       11997 non-null  object \n",
      " 1   Emitter_ID      11997 non-null  int64  \n",
      " 2   Radar_Function  11997 non-null  object \n",
      " 3   RF_MHz          11997 non-null  object \n",
      " 4   PW_us           11947 non-null  float64\n",
      " 5   PRI_us          11946 non-null  float64\n",
      " 6   Amplitude_dB    11945 non-null  float64\n",
      " 7   DOA_deg         11951 non-null  float64\n",
      " 8   Location_MGRS   11997 non-null  object \n",
      "dtypes: float64(4), int64(1), object(4)\n",
      "memory usage: 843.7+ KB\n",
      "\n",
      "\n",
      "\n",
      "EXAMPLE DATA:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Emitter_ID</th>\n",
       "      <th>Radar_Function</th>\n",
       "      <th>RF_MHz</th>\n",
       "      <th>PW_us</th>\n",
       "      <th>PRI_us</th>\n",
       "      <th>Amplitude_dB</th>\n",
       "      <th>DOA_deg</th>\n",
       "      <th>Location_MGRS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7512</th>\n",
       "      <td>2025-12-13 16:56:57</td>\n",
       "      <td>7</td>\n",
       "      <td>Target Illumination</td>\n",
       "      <td>10458.54412226765</td>\n",
       "      <td>3.293423</td>\n",
       "      <td>56.033804</td>\n",
       "      <td>2.416301</td>\n",
       "      <td>216.378221</td>\n",
       "      <td>51STV518067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Timestamp  Emitter_ID       Radar_Function             RF_MHz  \\\n",
       "7512  2025-12-13 16:56:57           7  Target Illumination  10458.54412226765   \n",
       "\n",
       "         PW_us     PRI_us  Amplitude_dB     DOA_deg Location_MGRS  \n",
       "7512  3.293423  56.033804      2.416301  216.378221   51STV518067  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#------------------------\n",
    "# Load and inspect data\n",
    "#------------------------\n",
    "\n",
    "df = pd.read_csv(\"data/pdw_dataset.csv\")\n",
    "df.info()\n",
    "print('\\n\\n\\nEXAMPLE DATA:')\n",
    "display(df.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1043873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PW_us</th>\n",
       "      <th>PRI_us</th>\n",
       "      <th>Amplitude_dB</th>\n",
       "      <th>DOA_deg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11947.000000</td>\n",
       "      <td>11946.000000</td>\n",
       "      <td>11945.000000</td>\n",
       "      <td>11951.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.200409</td>\n",
       "      <td>342.179367</td>\n",
       "      <td>11.433984</td>\n",
       "      <td>161.387265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.575861</td>\n",
       "      <td>246.304471</td>\n",
       "      <td>6.519501</td>\n",
       "      <td>112.952144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>36.389272</td>\n",
       "      <td>-9.927856</td>\n",
       "      <td>-42.229623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.018049</td>\n",
       "      <td>115.536763</td>\n",
       "      <td>6.958043</td>\n",
       "      <td>53.166461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.840423</td>\n",
       "      <td>352.676286</td>\n",
       "      <td>11.452169</td>\n",
       "      <td>175.610490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.131354</td>\n",
       "      <td>450.170770</td>\n",
       "      <td>15.952548</td>\n",
       "      <td>266.353439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.744222</td>\n",
       "      <td>857.814994</td>\n",
       "      <td>34.055909</td>\n",
       "      <td>396.585883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              PW_us        PRI_us  Amplitude_dB       DOA_deg\n",
       "count  11947.000000  11946.000000  11945.000000  11951.000000\n",
       "mean       2.200409    342.179367     11.433984    161.387265\n",
       "std        1.575861    246.304471      6.519501    112.952144\n",
       "min        0.010000     36.389272     -9.927856    -42.229623\n",
       "25%        1.018049    115.536763      6.958043     53.166461\n",
       "50%        1.840423    352.676286     11.452169    175.610490\n",
       "75%        3.131354    450.170770     15.952548    266.353439\n",
       "max        6.744222    857.814994     34.055909    396.585883"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['RF_MHz', 'PW_us', 'PRI_us', 'Amplitude_dB', 'DOA_deg']\n",
    "df[['RF_MHz', 'PW_us', 'PRI_us', 'Amplitude_dB', 'DOA_deg']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d73afcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------\n",
    "# Data Cleaning\n",
    "#------------------------\n",
    "\n",
    "def clean_df(df):\n",
    "    \"\"\"\n",
    "    First function to be called to clean the dataframe by converting feature columns to numeric, converting timestamps to datetime and reordering the columns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame -> The dataframe to be cleaned.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame ->A cleaned version of the dataframe.\n",
    "    \"\"\"\n",
    "    # Variables\n",
    "    clean_df = df.copy()\n",
    "    feature_cols = ['RF_MHz', 'PW_us', 'PRI_us', 'Amplitude_dB']\n",
    "    \n",
    "    # Dtype Conversions\n",
    "    for col in feature_cols:\n",
    "        clean_df[col] = pd.to_numeric(clean_df[col], errors='coerce')  # Convert strings or bad values to NaN\n",
    "    \n",
    "    date_time = pd.to_datetime(clean_df['Timestamp'])\n",
    "    clean_df['Date'] = date_time.dt.date   # Convert to datetime\n",
    "    clean_df['Time'] = date_time.dt.time   # Convert to datetime\n",
    "    clean_df['DDHHMMZ'] = date_time.dt.strftime('%d%H%MZ')\n",
    "\n",
    "    # Remove duplicate rows and missing data\n",
    "    clean_df = clean_df.dropna()\n",
    "    clean_df = clean_df.drop_duplicates(keep='last')\n",
    "\n",
    "   # Generate Report\n",
    "    julian_day = datetime.now().strftime('%j')\n",
    "    dt_now = datetime.now().strftime('%d%H%M')\n",
    "\n",
    "    header = 'EXERCISE EXERCISE EXERCISE'\n",
    "    classification = 'U N C L A S S I F I E D'\n",
    "    op_line = 'OPER/GALVANIZE//'\n",
    "    msgid = f'MSGID/FAKEREP/BC/{julian_day}//'\n",
    "    clean_df['SOI'] = clean_df.apply(lambda x: (f'SOI/-/{x['DDHHMMZ']}/{dt_now}Z/SYS_NOT/EMITTER_{x['Emitter_ID']})//'), axis=1)\n",
    "    clean_df['NARR'] = clean_df.apply(lambda x: (f\"\"\"NARR: ON {x['Date']} {x['Radar_Function'].upper()} SYSTEM (EMITTER_{x['Emitter_ID']}) WAS OBSERVED IVO {x['Location_MGRS']}.\"\"\"), axis=1)\n",
    "    clean_df['PARAMS'] = clean_df.apply(lambda x: (f\"\"\"PRMS/FREQ:{x['RF_MHz']:.4f} MHZ/PRI:{x['PRI_us']:010.3f}/PW:{x['PW_us']:.3f}/AMP:{x['Amplitude_dB']:.3f}DB/\\nDOA:{x['DOA_deg']:.3f} DEGREES\"\"\"), axis=1)\n",
    "    ampl_line = 'AMPL/AUTOGENERATED WITH MACHINE LEARNING//'\n",
    "    \n",
    "    def char_limit(row):\n",
    "        limit = textwrap.fill(row, width=69)\n",
    "        return limit\n",
    "\n",
    "    clean_df['NARR'] = clean_df['NARR'].apply(char_limit)\n",
    "\n",
    "    clean_df['Report'] = clean_df.apply(lambda x: (f\"\"\"{header}\\n{classification}\\n{op_line}\\n{msgid}\\n{x['SOI']}\\n{x['NARR'].replace(' / ', '/')}\\n{x['PARAMS']}\\n{ampl_line}\"\"\"), axis=1)\n",
    "\n",
    "    # Reorder\n",
    "    clean_df = clean_df[['Date', 'Time', 'Emitter_ID', 'Radar_Function', 'RF_MHz', 'PW_us', 'PRI_us', 'Amplitude_dB', 'DOA_deg', 'Location_MGRS', 'Report']] # Reorder\n",
    "    clean_df = clean_df.sort_values(by='Date').reset_index(drop=True)  # Arrange by date\n",
    "\n",
    "    return clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f48c6848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11643 entries, 0 to 11642\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Date            11643 non-null  object \n",
      " 1   Time            11643 non-null  object \n",
      " 2   Emitter_ID      11643 non-null  int64  \n",
      " 3   Radar_Function  11643 non-null  object \n",
      " 4   RF_MHz          11643 non-null  float64\n",
      " 5   PW_us           11643 non-null  float64\n",
      " 6   PRI_us          11643 non-null  float64\n",
      " 7   Amplitude_dB    11643 non-null  float64\n",
      " 8   DOA_deg         11643 non-null  float64\n",
      " 9   Location_MGRS   11643 non-null  object \n",
      " 10  Report          11643 non-null  object \n",
      "dtypes: float64(5), int64(1), object(5)\n",
      "memory usage: 1000.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Emitter_ID</th>\n",
       "      <th>Radar_Function</th>\n",
       "      <th>RF_MHz</th>\n",
       "      <th>PW_us</th>\n",
       "      <th>PRI_us</th>\n",
       "      <th>Amplitude_dB</th>\n",
       "      <th>DOA_deg</th>\n",
       "      <th>Location_MGRS</th>\n",
       "      <th>Report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-11-23</td>\n",
       "      <td>15:46:27</td>\n",
       "      <td>8</td>\n",
       "      <td>Medium-Range Search / Ground Mapping</td>\n",
       "      <td>9755.074702</td>\n",
       "      <td>1.950935</td>\n",
       "      <td>446.242790</td>\n",
       "      <td>13.020642</td>\n",
       "      <td>93.629260</td>\n",
       "      <td>51RWL215712</td>\n",
       "      <td>EXERCISE EXERCISE EXERCISE\\nU N C L A S S I F ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-11-23</td>\n",
       "      <td>15:40:12</td>\n",
       "      <td>8</td>\n",
       "      <td>Medium-Range Search / Ground Mapping</td>\n",
       "      <td>9788.016668</td>\n",
       "      <td>2.263802</td>\n",
       "      <td>447.778720</td>\n",
       "      <td>20.299857</td>\n",
       "      <td>93.808280</td>\n",
       "      <td>51RWL215712</td>\n",
       "      <td>EXERCISE EXERCISE EXERCISE\\nU N C L A S S I F ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-11-23</td>\n",
       "      <td>15:36:20</td>\n",
       "      <td>8</td>\n",
       "      <td>Medium-Range Search / Ground Mapping</td>\n",
       "      <td>9715.207387</td>\n",
       "      <td>3.137078</td>\n",
       "      <td>343.786447</td>\n",
       "      <td>10.824631</td>\n",
       "      <td>82.818948</td>\n",
       "      <td>51RWL215712</td>\n",
       "      <td>EXERCISE EXERCISE EXERCISE\\nU N C L A S S I F ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-11-23</td>\n",
       "      <td>15:50:09</td>\n",
       "      <td>8</td>\n",
       "      <td>Medium-Range Search / Ground Mapping</td>\n",
       "      <td>9724.553986</td>\n",
       "      <td>1.979538</td>\n",
       "      <td>402.121175</td>\n",
       "      <td>23.705022</td>\n",
       "      <td>108.880139</td>\n",
       "      <td>51RWL215712</td>\n",
       "      <td>EXERCISE EXERCISE EXERCISE\\nU N C L A S S I F ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-11-23</td>\n",
       "      <td>15:16:33</td>\n",
       "      <td>8</td>\n",
       "      <td>Medium-Range Search / Ground Mapping</td>\n",
       "      <td>9765.702453</td>\n",
       "      <td>1.667303</td>\n",
       "      <td>353.210397</td>\n",
       "      <td>18.471690</td>\n",
       "      <td>100.283732</td>\n",
       "      <td>51RWL215712</td>\n",
       "      <td>EXERCISE EXERCISE EXERCISE\\nU N C L A S S I F ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Time  Emitter_ID                        Radar_Function  \\\n",
       "0  2025-11-23  15:46:27           8  Medium-Range Search / Ground Mapping   \n",
       "1  2025-11-23  15:40:12           8  Medium-Range Search / Ground Mapping   \n",
       "2  2025-11-23  15:36:20           8  Medium-Range Search / Ground Mapping   \n",
       "3  2025-11-23  15:50:09           8  Medium-Range Search / Ground Mapping   \n",
       "4  2025-11-23  15:16:33           8  Medium-Range Search / Ground Mapping   \n",
       "\n",
       "        RF_MHz     PW_us      PRI_us  Amplitude_dB     DOA_deg Location_MGRS  \\\n",
       "0  9755.074702  1.950935  446.242790     13.020642   93.629260   51RWL215712   \n",
       "1  9788.016668  2.263802  447.778720     20.299857   93.808280   51RWL215712   \n",
       "2  9715.207387  3.137078  343.786447     10.824631   82.818948   51RWL215712   \n",
       "3  9724.553986  1.979538  402.121175     23.705022  108.880139   51RWL215712   \n",
       "4  9765.702453  1.667303  353.210397     18.471690  100.283732   51RWL215712   \n",
       "\n",
       "                                              Report  \n",
       "0  EXERCISE EXERCISE EXERCISE\\nU N C L A S S I F ...  \n",
       "1  EXERCISE EXERCISE EXERCISE\\nU N C L A S S I F ...  \n",
       "2  EXERCISE EXERCISE EXERCISE\\nU N C L A S S I F ...  \n",
       "3  EXERCISE EXERCISE EXERCISE\\nU N C L A S S I F ...  \n",
       "4  EXERCISE EXERCISE EXERCISE\\nU N C L A S S I F ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#------------------------\n",
    "# Apply Cleaning Functions\n",
    "#------------------------\n",
    "\n",
    "new_df = clean_df(df)\n",
    "new_df.info()\n",
    "display(new_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ba6470d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXERCISE EXERCISE EXERCISE\n",
      "U N C L A S S I F I E D\n",
      "OPER/GALVANIZE//\n",
      "MSGID/FAKEREP/BC/350//\n",
      "SOI/-/231546Z/162305Z/SYS_NOT/EMITTER_8)//\n",
      "NARR: ON 2025-11-23 MEDIUM-RANGE SEARCH/GROUND MAPPING SYSTEM\n",
      "(EMITTER_8) WAS OBSERVED IVO 51RWL215712.\n",
      "PRMS/FREQ:9755.0747 MHZ/PRI:000446.243/PW:1.951/AMP:13.021DB/\n",
      "DOA:93.629 DEGREES\n",
      "AMPL/AUTOGENERATED WITH MACHINE LEARNING//\n"
     ]
    }
   ],
   "source": [
    "print(new_df['Report'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f43068b",
   "metadata": {},
   "source": [
    "## Data Prep for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0bb49a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------\n",
    "# Split data into features and target\n",
    "#------------------------\n",
    "\n",
    "X = new_df.drop(columns=['Date', 'Time', 'Emitter_ID', 'Radar_Function', 'DOA_deg', 'Location_MGRS', 'Report'], axis=1)\n",
    "y = new_df['Emitter_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07a02378",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------\n",
    "# Classify features\n",
    "#------------------------\n",
    "\n",
    "numeric_features = X.select_dtypes(include=['float', 'int']).columns\n",
    "categorical_features = X.select_dtypes(include='object').columns\n",
    "\n",
    "#------------------------\n",
    "# Split into train and test sets\n",
    "#------------------------\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "    test_size=0.2, random_state=42)\n",
    "\n",
    "# Adjustments for XGBoost and LightGBM models because they require 0-indexing\n",
    "if y.min() == 1:        \n",
    "    y_train_adj = y_train - 1\n",
    "    y_test_adj = y_test - 1\n",
    "else:\n",
    "    y_train_adj = y_train.copy()\n",
    "    y_test_adj = y_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471aa392",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56a153f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------\n",
    "# Data Transformers\n",
    "# -----------------------------\n",
    "  \n",
    "num_xformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', MinMaxScaler())])\n",
    "# PolynomialFeatures for Logistic Regression ONLY\n",
    "num_xformer_poly = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        (\"poly\", PolynomialFeatures(degree=2, include_bias=False)),\n",
    "        ('scaler', MinMaxScaler())])  \n",
    "\n",
    "cat_xformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "        (\"onehot\", OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"))])\n",
    "# Create pipelines for CatBoost without OneHotEncoder\n",
    "cat_xformer_cb = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\"))])\n",
    "\n",
    "#------------------------------\n",
    "# Preprocessors\n",
    "# -----------------------------\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "        (\"num\", num_xformer, numeric_features),\n",
    "        (\"cat\", cat_xformer, categorical_features)], \n",
    "        remainder=\"drop\")\n",
    "preprocessor.set_output(transform=\"pandas\") # to retain column names\n",
    "\n",
    "preprocessor_poly = ColumnTransformer(transformers=[\n",
    "        (\"num\", num_xformer_poly, numeric_features),\n",
    "        (\"cat\", cat_xformer, categorical_features)], \n",
    "        remainder=\"drop\")\n",
    "preprocessor_poly.set_output(transform=\"pandas\") # to retain column names\n",
    "\n",
    "# Preprocessing for CatBoost\n",
    "cb_preprocessor = ColumnTransformer(transformers=[\n",
    "        (\"num\", num_xformer, numeric_features),\n",
    "        (\"cat\", cat_xformer_cb, categorical_features)], \n",
    "        remainder=\"drop\")\n",
    "cb_preprocessor.set_output(transform=\"pandas\") # to retain column names\n",
    "\n",
    "#------------------------------\n",
    "# Model Pipes\n",
    "# -----------------------------\n",
    "\n",
    "logistic_pipe = Pipeline(steps=[\n",
    "        (\"preprocess\", preprocessor_poly),\n",
    "        (\"model\", LogisticRegression(max_iter=1000, random_state=42))])\n",
    "    \n",
    "tree_pipe = Pipeline(steps=[\n",
    "        (\"preprocess\", preprocessor),\n",
    "        (\"model\", DecisionTreeClassifier(random_state=42))])\n",
    "\n",
    "forest_pipe = Pipeline(steps=[\n",
    "        (\"preprocess\", preprocessor),\n",
    "        (\"model\", RandomForestClassifier(max_depth=12, min_samples_split=7, n_estimators=63, random_state=42))])\n",
    "\n",
    "xgb_pipe = Pipeline(steps=[\n",
    "        (\"preprocess\", preprocessor),\n",
    "        (\"model\", XGBClassifier(random_state=42))])\n",
    "\n",
    "lgbm_pipe = Pipeline(steps=[\n",
    "        (\"preprocess\", preprocessor),\n",
    "        (\"model\", LGBMClassifier(verbose=-1, random_state=42))])\n",
    "\n",
    "cat_pipe = Pipeline(steps=[\n",
    "        (\"preprocess\", cb_preprocessor),\n",
    "        (\"model\", CatBoostClassifier(verbose=0, random_state=42))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc4b56d",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "baec6c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9405\n",
      "Accuracy Score: 94.55%\n"
     ]
    }
   ],
   "source": [
    "#------------------------------\n",
    "# Logistic Regression Pipe\n",
    "# -----------------------------\n",
    "\n",
    "logistic_pipe.fit(X_train, y_train)\n",
    "y_pred = logistic_pipe.predict(X_test)\n",
    "\n",
    "print(f'F1 Score: {f1_score(y_test, y_pred, average=\"weighted\"):.4f}')\n",
    "print(f'Accuracy Score: {accuracy_score(y_test, y_pred)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f529b955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9707\n",
      "Accuracy Score: 97.04%\n"
     ]
    }
   ],
   "source": [
    "#------------------------------\n",
    "# Decision Tree Pipe\n",
    "# -----------------------------\n",
    "\n",
    "tree_pipe.fit(X_train, y_train)\n",
    "y_pred = tree_pipe.predict(X_test)\n",
    "\n",
    "print(f'F1 Score: {f1_score(y_test, y_pred, average=\"weighted\"):.4f}')\n",
    "print(f'Accuracy Score: {accuracy_score(y_test, y_pred)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "399001a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9811\n",
      "Accuracy Score: 98.11%\n"
     ]
    }
   ],
   "source": [
    "#------------------------------\n",
    "# Random Forest Pipe\n",
    "# -----------------------------\n",
    "\n",
    "forest_pipe.fit(X_train, y_train)\n",
    "y_pred = forest_pipe.predict(X_test)\n",
    "\n",
    "print(f'F1 Score: {f1_score(y_test, y_pred, average=\"weighted\"):.4f}')\n",
    "print(f'Accuracy Score: {accuracy_score(y_test, y_pred)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7d0e44cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9689\n",
      "Accuracy Score: 96.87%\n"
     ]
    }
   ],
   "source": [
    "#------------------------------\n",
    "# XGBoost Pipe\n",
    "# -----------------------------\n",
    "\n",
    "xgb_pipe.fit(X_train, y_train_adj)\n",
    "y_pred = xgb_pipe.predict(X_test)\n",
    "\n",
    "print(f'F1 Score: {f1_score(y_test_adj, y_pred, average=\"weighted\"):.4f}')\n",
    "print(f'Accuracy Score: {accuracy_score(y_test_adj, y_pred)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c7b0345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9703\n",
      "Accuracy Score: 96.99%\n"
     ]
    }
   ],
   "source": [
    "#------------------------------\n",
    "# LightGBM Pipe\n",
    "# -----------------------------\n",
    "\n",
    "lgbm_pipe.fit(X_train, y_train_adj)\n",
    "y_pred = lgbm_pipe.predict(X_test)\n",
    "\n",
    "print(f'F1 Score: {f1_score(y_test_adj, y_pred, average=\"weighted\"):.4f}')\n",
    "print(f'Accuracy Score: {accuracy_score(y_test_adj, y_pred)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae52d20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9717\n",
      "Accuracy Score: 97.17%\n"
     ]
    }
   ],
   "source": [
    "#------------------------------\n",
    "# CatBoost Pipe\n",
    "# -----------------------------\n",
    "\n",
    "cat_pipe.fit(X_train, y_train)\n",
    "y_pred = cat_pipe.predict(X_test)\n",
    "\n",
    "print(f'F1 Score: {f1_score(y_test, y_pred, average=\"weighted\"):.4f}')\n",
    "print(f'Accuracy Score: {accuracy_score(y_test, y_pred)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a650967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression score: 94.05%\n",
      "Decision Tree score: 97.07%\n",
      "Random Forest score: 98.11%\n",
      "XGBoost score: 96.89%\n",
      "LightGBM score: 97.03%\n",
      "CatBoost score: 97.17%\n"
     ]
    }
   ],
   "source": [
    "#------------------------------\n",
    "# All Pipes\n",
    "# -----------------------------\n",
    "\n",
    "all_models = {\n",
    "    'Logistic Regression': logistic_pipe,\n",
    "    'Decision Tree': tree_pipe,\n",
    "    'Random Forest': forest_pipe,\n",
    "    'XGBoost': xgb_pipe,\n",
    "    'LightGBM': lgbm_pipe,\n",
    "    'CatBoost': cat_pipe\n",
    "}\n",
    "\n",
    "for name, model in all_models.items():\n",
    "    \n",
    "    if model == xgb_pipe or model == lgbm_pipe:\n",
    "        y_true = y_test_adj\n",
    "        model.fit(X_train, y_train_adj)\n",
    "    else:\n",
    "        y_true = y_test\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"{name} score: {f1 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db8062c",
   "metadata": {},
   "source": [
    "## Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7cf870cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------\n",
    "# Parameter Dictionary for GridSearchCV\n",
    "# -----------------------------\n",
    "\n",
    "params_gridscv = {\n",
    "   \"Logistic Regression\": {\n",
    "       'pipe': logistic_pipe,\n",
    "       'grid': {\n",
    "            'model__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100], # Regularization - penalized for large coefficients\n",
    "            'model__max_iter': [1000]                   # Increased number of passes for solver to run\n",
    "    }},\n",
    "\n",
    "    \"Decision Tree\": {\n",
    "        'pipe': tree_pipe,\n",
    "        'grid': {\n",
    "            'model__max_depth': [2, 3, 5, 7, 10, None], # Depth of tree decisions\n",
    "            'model__min_samples_split': [2, 3, 5, 7],   # Minimum num of samples required at each node\n",
    "            'model__min_samples_leaf': [2, 5, 7, 10]    # Minimum num of samples required at each final grouping\n",
    "    }},\n",
    "\n",
    "    \"Random Forest\": {\n",
    "        'pipe': forest_pipe,\n",
    "        'grid': {    \n",
    "            'model__n_estimators': [100, 200, 400],  # Number of trees\n",
    "            'model__max_depth': [10, 15, None],      # Depth of tree decisions\n",
    "            'model__min_samples_split': [2, 3, 5, 7] # minimum num of samples required at each node\n",
    "    }}\n",
    "}\n",
    "\n",
    "#------------------------------\n",
    "# Parameter Dictionary for RandomizedSearchCV\n",
    "# -----------------------------\n",
    "\n",
    "params_randomscv = {\n",
    "    'XGBoost': {\n",
    "        'pipe': xgb_pipe,\n",
    "        'dist': {\n",
    "            'model__learning_rate': stats.uniform(.03, .2),     # Range 0.03 to 0.23\n",
    "            'model__n_estimators': stats.randint(100, 1000),    # Number of boosting stages\n",
    "            'model__max_depth': stats.randint(3, 8)             # Tree complexity\n",
    "    }},\n",
    "\n",
    "    'LightGBM': {\n",
    "        'pipe': lgbm_pipe,\n",
    "        'dist': {\n",
    "            'model__learning_rate': stats.uniform(.03, .2),     # Range 0.03 to 0.23\n",
    "            'model__n_estimators': stats.randint(100, 500),     # Number of boosting stages\n",
    "            'model__num_leaves': stats.randint(10, 100)         # Tree complexity\n",
    "\n",
    "    }},\n",
    "\n",
    "    'CatBoost': {\n",
    "        'pipe': cat_pipe,\n",
    "        'dist': {\n",
    "            'model__learning_rate': stats.uniform(.03, .2),     # Range 0.03 to 0.23\n",
    "            'model__iterations': stats.randint(100, 1000),      # Number of instance\n",
    "            'model__max_depth': stats.randint(3, 10),           # Complexity\n",
    "    }}\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7e75b53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting GridSearchCV for selected models...\n",
      "\n",
      "Tuning Logistic Regression...\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      " -> Precision = 0.9655, Recall = 0.9665, F1 = 0.9640\n",
      "\n",
      "Tuning Decision Tree...\n",
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      " -> Precision = 0.9737, Recall = 0.9721, F1 = 0.9726\n",
      "\n",
      "Tuning Random Forest...\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      " -> Precision = 0.9776, Recall = 0.9772, F1 = 0.9774\n",
      "\n",
      "GrudSearchCV complete.\n"
     ]
    }
   ],
   "source": [
    "#------------------------------\n",
    "# Running GridSearchCV on Logistic Regression, Decision Tree, and Random Forest\n",
    "# -----------------------------\n",
    "\n",
    "print(\"Starting GridSearchCV for selected models...\")\n",
    "results = {}\n",
    "\n",
    "for name, params in params_gridscv.items():\n",
    "    print(f\"\\nTuning {name}...\")\n",
    "    \n",
    "    grid_scv = GridSearchCV(\n",
    "        estimator=params['pipe'], \n",
    "        param_grid=params['grid'], \n",
    "        scoring='f1_weighted', # Metric: F1 Score Weighted\n",
    "        cv=5,                 # 5-fold cross-validation\n",
    "        n_jobs=-1,            # Use all available cores\n",
    "        verbose=1             # Print progress\n",
    "    )\n",
    "    \n",
    "    grid_scv.fit(X_train, y_train)\n",
    "    y_preds = grid_scv.predict(X_test)\n",
    "    \n",
    "    prec = precision_score(y_test, y_preds, average='weighted')\n",
    "    recall = recall_score(y_test, y_preds, average='weighted')\n",
    "    f1 = f1_score(y_test, y_preds, average='weighted')\n",
    "\n",
    "    # Store and print results\n",
    "    results[name] = {\n",
    "        'best_score': grid_scv.best_score_,\n",
    "        'best_params': grid_scv.best_params_\n",
    "    }\n",
    "    print(f' -> Precision = {prec:.4f}, Recall = {recall:.4f}, F1 = {f1:.4f}')\n",
    "\n",
    "print(\"\\nGrudSearchCV complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fbe1970f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression best score: 0.9642\n",
      "Logistic Regression best params: {'model__C': 100, 'model__max_iter': 1000}\n",
      "\n",
      "Decision Tree best score: 0.9723\n",
      "Decision Tree best params: {'model__max_depth': None, 'model__min_samples_leaf': 10, 'model__min_samples_split': 2}\n",
      "\n",
      "Random Forest best score: 0.9765\n",
      "Random Forest best params: {'model__max_depth': None, 'model__min_samples_split': 2, 'model__n_estimators': 100}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#------------------------------\n",
    "# GridSearchCV Results\n",
    "# -----------------------------\n",
    "\n",
    "for name, result in results.items():\n",
    "    print(f\"{name} best score: {result['best_score']:.4f}\")\n",
    "    print(f\"{name} best params: {result['best_params']}\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "41816e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting RandomSearchCV for boost models...\n",
      "\n",
      "Tuning XGBoost...\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      " -> Precision = 0.9776, Recall = 0.9772, F1 = 0.9774\n",
      "\n",
      "Tuning LightGBM...\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      " -> Precision = 0.9776, Recall = 0.9772, F1 = 0.9774\n",
      "\n",
      "Tuning CatBoost...\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      " -> Precision = 0.9776, Recall = 0.9772, F1 = 0.9774\n"
     ]
    }
   ],
   "source": [
    "#------------------------------\n",
    "# Running RandomSearchCV on XGBoost, LightGBM, and CatBoost\n",
    "# -----------------------------\n",
    "\n",
    "print(\"Starting RandomSearchCV for boost models...\")\n",
    "results2 = {}\n",
    "\n",
    "for name, params in params_randomscv.items():\n",
    "    print(f\"\\nTuning {name}...\")\n",
    "    \n",
    "    rando_scv = RandomizedSearchCV(\n",
    "        estimator=params['pipe'], \n",
    "        param_distributions=params['dist'], \n",
    "        scoring='f1_weighted', # Metric: F1 Score Weighted\n",
    "        cv=3,                 # 5-fold cross-validation\n",
    "        n_jobs=-1,            # Use all available cores\n",
    "        verbose=1             # Print progress\n",
    "    )\n",
    "    \n",
    "    if name == 'XGBoost' or name == 'LightGBM':\n",
    "        rando_scv.fit(X_train, y_train_adj)\n",
    "        y_true = y_test_adj\n",
    "    else:\n",
    "        rando_scv.fit(X_train, y_train)\n",
    "        y_true = y_test\n",
    "\n",
    "    y_preds2 = rando_scv.predict(X_test)\n",
    "    \n",
    "    prec2 = precision_score(y_test, y_preds, average='weighted')\n",
    "    recall2 = recall_score(y_test, y_preds, average='weighted')\n",
    "    f1_2 = f1_score(y_test, y_preds, average='weighted')\n",
    "\n",
    "    # Store and print results\n",
    "    results2[name] = {\n",
    "        'best_score': rando_scv.best_score_,\n",
    "        'best_params': rando_scv.best_params_\n",
    "    }\n",
    "    print(f' -> Precision = {prec2:.4f}, Recall = {recall2:.4f}, F1 = {f1_2:.4f}')\n",
    "\n",
    "print(\"\\nRandomSearchCV complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fbf313fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost best score: 0.9747\n",
      "XGBoost best params: {'model__learning_rate': np.float64(0.06496044215937306), 'model__max_depth': 3, 'model__n_estimators': 238}\n",
      "\n",
      "LightGBM best score: 0.9724\n",
      "LightGBM best params: {'model__learning_rate': np.float64(0.1501089469576768), 'model__n_estimators': 106, 'model__num_leaves': 74}\n",
      "\n",
      "CatBoost best score: 0.9765\n",
      "CatBoost best params: {'model__iterations': 775, 'model__learning_rate': np.float64(0.030851196164042166), 'model__max_depth': 3}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#------------------------------\n",
    "# RandomSearchCV Results\n",
    "# -----------------------------\n",
    "\n",
    "for name, result in results2.items():\n",
    "    print(f\"{name} best score: {result['best_score']:.4f}\")\n",
    "    print(f\"{name} best params: {result['best_params']}\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbfc6e4",
   "metadata": {},
   "source": [
    "### Mega-Tune!\n",
    "Random Forest outperformed the other models in both the base testing and cross validation. Let's perform one more GridSearchCV with just Random Forest using a larger array of hyperparameters to get it just right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "33da069d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------\n",
    "# Mega GridSearchCV\n",
    "# -----------------------------\n",
    "\n",
    "enhanced_gridscv = {\n",
    "    \"Decision Tree\": {\n",
    "        'pipe': tree_pipe,\n",
    "        'grid': {    \n",
    "            'model__min_samples_leaf': list(range(0, 101, 10)),  # Number of trees\n",
    "            'model__max_depth': list(range(1, 16, 2)),        # Depth of tree decisions\n",
    "            'model__min_samples_split': list(range(2, 10, 1)) # minimum num of samples required at each node\n",
    "    }}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b446eb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting comprehensive GridSearchCV...\n",
      "\n",
      "Tuning Decision Tree...\n",
      " -> Precision = 0.9737, Recall = 0.9721, F1 = 0.9726\n",
      "Decision Tree best score: 0.9728\n",
      "Decision Tree best params: {'model__max_depth': 13, 'model__min_samples_leaf': 10, 'model__min_samples_split': 2}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\burto\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning: \n",
      "320 fits failed out of a total of 3520.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "320 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\burto\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\burto\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\burto\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 662, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\burto\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\burto\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\burto\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_leaf' parameter of DecisionTreeClassifier must be an int in the range [1, inf) or a float in the range (0.0, 1.0). Got 0 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\burto\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.19472686 0.19472686 0.19472686 0.19472686\n",
      " 0.19472686 0.19472686 0.19472686 0.19472686 0.19472686 0.19472686\n",
      " 0.19472686 0.19472686 0.19472686 0.19472686 0.19472686 0.19472686\n",
      " 0.19472686 0.19472686 0.19472686 0.19472686 0.19472686 0.19472686\n",
      " 0.19472686 0.19472686 0.19472686 0.19472686 0.19472686 0.19472686\n",
      " 0.19472686 0.19472686 0.19472686 0.19472686 0.19472686 0.19472686\n",
      " 0.19472686 0.19472686 0.19472686 0.19472686 0.19472686 0.19472686\n",
      " 0.19472686 0.19472686 0.19472686 0.19472686 0.19472686 0.19472686\n",
      " 0.19472686 0.19472686 0.19472686 0.19472686 0.19472686 0.19472686\n",
      " 0.19472686 0.19472686 0.19472686 0.19472686 0.19472686 0.19472686\n",
      " 0.19472686 0.19472686 0.19472686 0.19472686 0.19472686 0.19472686\n",
      " 0.19472686 0.19472686 0.19472686 0.19472686 0.19472686 0.19472686\n",
      " 0.19472686 0.19472686 0.19472686 0.19472686 0.19472686 0.19472686\n",
      " 0.19472686 0.19472686 0.19472686 0.19472686        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.62091239 0.62091239 0.62091239 0.62091239 0.62091239 0.62091239\n",
      " 0.62091239 0.62091239 0.61784713 0.61784713 0.61784713 0.61784713\n",
      " 0.61784713 0.61784713 0.61784713 0.61784713 0.6171442  0.6171442\n",
      " 0.6171442  0.6171442  0.6171442  0.6171442  0.6171442  0.6171442\n",
      " 0.6171442  0.6171442  0.6171442  0.6171442  0.6171442  0.6171442\n",
      " 0.6171442  0.6171442  0.61707374 0.61707374 0.61707374 0.61707374\n",
      " 0.61707374 0.61707374 0.61707374 0.61707374 0.61686195 0.61686195\n",
      " 0.61686195 0.61686195 0.61686195 0.61686195 0.61686195 0.61686195\n",
      " 0.6164293  0.6164293  0.6164293  0.6164293  0.6164293  0.6164293\n",
      " 0.6164293  0.6164293  0.6157091  0.6157091  0.6157091  0.6157091\n",
      " 0.6157091  0.6157091  0.6157091  0.6157091  0.61284373 0.61284373\n",
      " 0.61284373 0.61284373 0.61284373 0.61284373 0.61284373 0.61284373\n",
      " 0.61213591 0.61213591 0.61213591 0.61213591 0.61213591 0.61213591\n",
      " 0.61213591 0.61213591        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.91018395 0.91018395\n",
      " 0.91018395 0.91018395 0.91018395 0.91018395 0.91018395 0.91018395\n",
      " 0.90832387 0.90832387 0.90832387 0.90832387 0.90832387 0.90832387\n",
      " 0.90832387 0.90832387 0.90616418 0.90616418 0.90616418 0.90616418\n",
      " 0.90616418 0.90616418 0.90616418 0.90616418 0.90616418 0.90616418\n",
      " 0.90616418 0.90616418 0.90616418 0.90616418 0.90616418 0.90616418\n",
      " 0.90469953 0.90469953 0.90469953 0.90469953 0.90469953 0.90469953\n",
      " 0.90469953 0.90469953 0.90458682 0.90458682 0.90458682 0.90458682\n",
      " 0.90458682 0.90458682 0.90458682 0.90458682 0.9027309  0.9027309\n",
      " 0.9027309  0.9027309  0.9027309  0.9027309  0.9027309  0.9027309\n",
      " 0.90155317 0.90155317 0.90155317 0.90155317 0.90155317 0.90155317\n",
      " 0.90155317 0.90155317 0.90104066 0.90104066 0.90104066 0.90104066\n",
      " 0.90104066 0.90104066 0.90104066 0.90104066 0.90033845 0.90033845\n",
      " 0.90033845 0.90033845 0.90033845 0.90033845 0.90033845 0.90033845\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.966346   0.966346   0.966346   0.966346\n",
      " 0.966346   0.966346   0.966346   0.966346   0.96388226 0.96388226\n",
      " 0.96388226 0.96388226 0.96388226 0.96388226 0.96388226 0.96388226\n",
      " 0.9634934  0.9634934  0.9634934  0.9634934  0.9634934  0.9634934\n",
      " 0.9634934  0.9634934  0.96250123 0.96250123 0.96250123 0.96250123\n",
      " 0.96250123 0.96250123 0.96250123 0.96250123 0.9579321  0.9579321\n",
      " 0.9579321  0.9579321  0.9579321  0.9579321  0.9579321  0.9579321\n",
      " 0.95631589 0.95631589 0.95631589 0.95631589 0.95631589 0.95631589\n",
      " 0.95631589 0.95631589 0.95062212 0.95062212 0.95062212 0.95062212\n",
      " 0.95062212 0.95062212 0.95062212 0.95062212 0.94714351 0.94714351\n",
      " 0.94714351 0.94714351 0.94714351 0.94714351 0.94714351 0.94714351\n",
      " 0.94060509 0.94060509 0.94060509 0.94060509 0.94060509 0.94060509\n",
      " 0.94060509 0.94060509 0.94016087 0.94016087 0.94016087 0.94016087\n",
      " 0.94016087 0.94016087 0.94016087 0.94016087        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.97203603 0.97203603 0.97203603 0.97203603 0.97203603 0.97203603\n",
      " 0.97203603 0.97203603 0.96958617 0.96958617 0.96958617 0.96958617\n",
      " 0.96958617 0.96958617 0.96958617 0.96958617 0.96870758 0.96870758\n",
      " 0.96870758 0.96870758 0.96870758 0.96870758 0.96870758 0.96870758\n",
      " 0.96715905 0.96715905 0.96715905 0.96715905 0.96715905 0.96715905\n",
      " 0.96715905 0.96715905 0.96227032 0.96227032 0.96227032 0.96227032\n",
      " 0.96227032 0.96227032 0.96227032 0.96227032 0.96161644 0.96161644\n",
      " 0.96161644 0.96161644 0.96161644 0.96161644 0.96161644 0.96161644\n",
      " 0.95340535 0.95340535 0.95340535 0.95340535 0.95340535 0.95340535\n",
      " 0.95340535 0.95340535 0.94909516 0.94909516 0.94909516 0.94909516\n",
      " 0.94909516 0.94909516 0.94909516 0.94909516 0.94247116 0.94247116\n",
      " 0.94247116 0.94247116 0.94247116 0.94247116 0.94247116 0.94247116\n",
      " 0.94112869 0.94112869 0.94112869 0.94112869 0.94112869 0.94112869\n",
      " 0.94112869 0.94112869        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.97167337 0.97167337\n",
      " 0.97167337 0.97167337 0.97167337 0.97167337 0.97167337 0.97167337\n",
      " 0.97042573 0.97042573 0.97042573 0.97042573 0.97042573 0.97042573\n",
      " 0.97042573 0.97042573 0.96938974 0.96938974 0.96938974 0.96938974\n",
      " 0.96938974 0.96938974 0.96938974 0.96938974 0.9685365  0.9685365\n",
      " 0.9685365  0.9685365  0.9685365  0.9685365  0.9685365  0.9685365\n",
      " 0.96290534 0.96290534 0.96290534 0.96290534 0.96290534 0.96290534\n",
      " 0.96290534 0.96290534 0.96161644 0.96161644 0.96161644 0.96161644\n",
      " 0.96161644 0.96161644 0.96161644 0.96161644 0.95340535 0.95340535\n",
      " 0.95340535 0.95340535 0.95340535 0.95340535 0.95340535 0.95340535\n",
      " 0.94909516 0.94909516 0.94909516 0.94909516 0.94909516 0.94909516\n",
      " 0.94909516 0.94909516 0.94247116 0.94247116 0.94247116 0.94247116\n",
      " 0.94247116 0.94247116 0.94247116 0.94247116 0.94112869 0.94112869\n",
      " 0.94112869 0.94112869 0.94112869 0.94112869 0.94112869 0.94112869\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.97278789 0.97278789 0.97278789 0.97278789\n",
      " 0.97278789 0.97278789 0.97278789 0.97278789 0.97035233 0.97035233\n",
      " 0.97035233 0.97035233 0.97035233 0.97035233 0.97035233 0.97035233\n",
      " 0.96938974 0.96938974 0.96938974 0.96938974 0.96938974 0.96938974\n",
      " 0.96938974 0.96938974 0.9685365  0.9685365  0.9685365  0.9685365\n",
      " 0.9685365  0.9685365  0.9685365  0.9685365  0.96290534 0.96290534\n",
      " 0.96290534 0.96290534 0.96290534 0.96290534 0.96290534 0.96290534\n",
      " 0.96161644 0.96161644 0.96161644 0.96161644 0.96161644 0.96161644\n",
      " 0.96161644 0.96161644 0.95340535 0.95340535 0.95340535 0.95340535\n",
      " 0.95340535 0.95340535 0.95340535 0.95340535 0.94909516 0.94909516\n",
      " 0.94909516 0.94909516 0.94909516 0.94909516 0.94909516 0.94909516\n",
      " 0.94247116 0.94247116 0.94247116 0.94247116 0.94247116 0.94247116\n",
      " 0.94247116 0.94247116 0.94112869 0.94112869 0.94112869 0.94112869\n",
      " 0.94112869 0.94112869 0.94112869 0.94112869        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.97254536 0.97254536 0.97254536 0.97254536 0.97254536 0.97254536\n",
      " 0.97254536 0.97254536 0.97035233 0.97035233 0.97035233 0.97035233\n",
      " 0.97035233 0.97035233 0.97035233 0.97035233 0.96938974 0.96938974\n",
      " 0.96938974 0.96938974 0.96938974 0.96938974 0.96938974 0.96938974\n",
      " 0.9685365  0.9685365  0.9685365  0.9685365  0.9685365  0.9685365\n",
      " 0.9685365  0.9685365  0.96290534 0.96290534 0.96290534 0.96290534\n",
      " 0.96290534 0.96290534 0.96290534 0.96290534 0.96161644 0.96161644\n",
      " 0.96161644 0.96161644 0.96161644 0.96161644 0.96161644 0.96161644\n",
      " 0.95340535 0.95340535 0.95340535 0.95340535 0.95340535 0.95340535\n",
      " 0.95340535 0.95340535 0.94909516 0.94909516 0.94909516 0.94909516\n",
      " 0.94909516 0.94909516 0.94909516 0.94909516 0.94247116 0.94247116\n",
      " 0.94247116 0.94247116 0.94247116 0.94247116 0.94247116 0.94247116\n",
      " 0.94112869 0.94112869 0.94112869 0.94112869 0.94112869 0.94112869\n",
      " 0.94112869 0.94112869]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# #------------------------------\n",
    "# # Running Mega GridSearchCV on Random Forest\n",
    "# # -----------------------------\n",
    "\n",
    "print(\"Starting comprehensive GridSearchCV...\")\n",
    "results3 = {}\n",
    "\n",
    "for name, params in enhanced_gridscv.items():\n",
    "    print(f\"\\nTuning {name}...\")\n",
    "    \n",
    "    grid_scv2 = GridSearchCV(\n",
    "        estimator=params['pipe'], \n",
    "        param_grid=params['grid'], \n",
    "        scoring='f1_weighted',   # Metric: F1 Score Weighted\n",
    "        cv=5,                    # 5-fold cross-validation\n",
    "        n_jobs=-1,               # Use all available cores\n",
    "        verbose=0,               # Print progress dismissed\n",
    "        error_score= np.nan      # Ignore errors\n",
    "    )\n",
    "    \n",
    "    grid_scv2.fit(X_train, y_train)\n",
    "    y_preds = grid_scv2.predict(X_test)\n",
    "    \n",
    "    prec = precision_score(y_test, y_preds, average='weighted')\n",
    "    recall = recall_score(y_test, y_preds, average='weighted')\n",
    "    f1 = f1_score(y_test, y_preds, average='weighted')\n",
    "\n",
    "    # Store and print results\n",
    "    results3[name] = {\n",
    "        'best_score': grid_scv2.best_score_,\n",
    "        'best_params': grid_scv2.best_params_\n",
    "    }\n",
    "\n",
    "    print(f' -> Precision = {prec:.4f}, Recall = {recall:.4f}, F1 = {f1:.4f}')\n",
    "\n",
    "    for name, result in results3.items():\n",
    "        print(f\"{name} best score: {result['best_score']:.4f}\")\n",
    "        print(f\"{name} best params: {result['best_params']}\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f9333a",
   "metadata": {},
   "source": [
    "## Reports Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8692648",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m sys_of_interest = [\u001b[33m'\u001b[39m\u001b[33mShort-Range Fire Control / Tracking\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mTarget Acquisition / Tracking\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mTarget Illumination\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;66;03m# Use in streamlit\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m filtered_df = \u001b[43mnew_df\u001b[49m[new_df[\u001b[33m'\u001b[39m\u001b[33mRadar_Function\u001b[39m\u001b[33m'\u001b[39m].isin(sys_of_interest)]\n\u001b[32m      4\u001b[39m filtered_df = filtered_df.reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      5\u001b[39m filtered_df.info()    \n",
      "\u001b[31mNameError\u001b[39m: name 'new_df' is not defined"
     ]
    }
   ],
   "source": [
    "sys_of_interest = ['Short-Range Fire Control / Tracking', 'Target Acquisition / Tracking', 'Target Illumination'] # Use in streamlit\n",
    "filtered_df = new_df[new_df['Radar_Function'].isin(sys_of_interest)]\n",
    "\n",
    "filtered_df = filtered_df.reset_index(drop=True)\n",
    "filtered_df.info()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "437e54ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filtered_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m display(\u001b[43mfiltered_df\u001b[49m.head())\n",
      "\u001b[31mNameError\u001b[39m: name 'filtered_df' is not defined"
     ]
    }
   ],
   "source": [
    "display(filtered_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e0a24aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_mod = joblib.load('ml_models/logistic_regression.pkl')\n",
    "tree_mod = joblib.load('ml_models/decision_tree.pkl')\n",
    "forest_mod = joblib.load('ml_models/random_forest.pkl')\n",
    "xgb_mod = joblib.load('ml_models/xgboost.pkl')\n",
    "lgb_mod = joblib.load('ml_models/lightgbm.pkl')\n",
    "cb_mod = joblib.load('ml_models/catboost.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7bbd92e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metadata = {'size (kb)' : {'Logistic Regression' : os.path.getsize('ml_models/logistic_regression.pkl') / 1024,\n",
    "                              'Decision Tree' : os.path.getsize('ml_models/decision_tree.pkl') / 1024,\n",
    "                              'Random Forest' : os.path.getsize('ml_models/random_forest.pkl') / 1024,\n",
    "                              'XG Boost' : os.path.getsize('ml_models/xgboost.pkl') / 1024,\n",
    "                              'LightGBM' : os.path.getsize('ml_models/lightgbm.pkl') / 1024,\n",
    "                              'CatBoost' : os.path.getsize('ml_models/catboost.pkl') / 1024},   \n",
    "                    'accuracy' : {'Logistic Regression' : log_mod['metadata']['accuracy'],\n",
    "                                  'Decision Tree' : tree_mod['metadata']['accuracy'],\n",
    "                                  'Random Forest' : forest_mod['metadata']['accuracy'],\n",
    "                                  'XG Boost' : xgb_mod['metadata']['accuracy'],\n",
    "                                  'LightGBM' : lgb_mod['metadata']['accuracy'],\n",
    "                                  'CatBoost' : cb_mod['metadata']['accuracy']},\n",
    "                    'f1_score' : {'Logistic Regression' : log_mod['metadata']['f1_score_weighted'],\n",
    "                                  'Decision Tree' : tree_mod['metadata']['f1_score_weighted'],\n",
    "                                  'Random Forest' : forest_mod['metadata']['f1_score_weighted'],\n",
    "                                  'XG Boost' : xgb_mod['metadata']['f1_score_weighted'],\n",
    "                                  'LightGBM' : lgb_mod['metadata']['f1_score_weighted'],\n",
    "                                  'CatBoost' : cb_mod['metadata']['f1_score_weighted']},\n",
    "                    'train_time' : {'Logistic Regression' : log_mod['metadata']['train_time_sec'],\n",
    "                                  'Decision Tree' : tree_mod['metadata']['train_time_sec'],\n",
    "                                  'Random Forest' : forest_mod['metadata']['train_time_sec'],\n",
    "                                  'XG Boost' : xgb_mod['metadata']['train_time_sec'],\n",
    "                                  'LightGBM' : lgb_mod['metadata']['train_time_sec'],\n",
    "                                  'CatBoost' : cb_mod['metadata']['train_time_sec']}}\n",
    "\n",
    "model_df = pd.DataFrame(model_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ccade40b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size (kb)</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>train_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>7.612305</td>\n",
       "      <td>0.967368</td>\n",
       "      <td>0.965573</td>\n",
       "      <td>0.298234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>30.139648</td>\n",
       "      <td>0.972091</td>\n",
       "      <td>0.972565</td>\n",
       "      <td>0.038235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>2068.443359</td>\n",
       "      <td>0.978961</td>\n",
       "      <td>0.979037</td>\n",
       "      <td>0.648392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XG Boost</th>\n",
       "      <td>2033.997070</td>\n",
       "      <td>0.973379</td>\n",
       "      <td>0.973575</td>\n",
       "      <td>0.860013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>1954.504883</td>\n",
       "      <td>0.973379</td>\n",
       "      <td>0.973622</td>\n",
       "      <td>0.615320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost</th>\n",
       "      <td>329.891602</td>\n",
       "      <td>0.975955</td>\n",
       "      <td>0.975941</td>\n",
       "      <td>2.002023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       size (kb)  accuracy  f1_score  train_time\n",
       "Logistic Regression     7.612305  0.967368  0.965573    0.298234\n",
       "Decision Tree          30.139648  0.972091  0.972565    0.038235\n",
       "Random Forest        2068.443359  0.978961  0.979037    0.648392\n",
       "XG Boost             2033.997070  0.973379  0.973575    0.860013\n",
       "LightGBM             1954.504883  0.973379  0.973622    0.615320\n",
       "CatBoost              329.891602  0.975955  0.975941    2.002023"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df.head(6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
